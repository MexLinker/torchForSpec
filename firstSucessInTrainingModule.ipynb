{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09601b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spectral as spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78043a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.__version__\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch  # 导入pytorch\n",
    "from torch import nn, optim  # 导入神经网络与优化器对应的类\n",
    "import torch.nn.functional as F \n",
    "from torchvision import datasets, transforms ## 导入数据集与数据预处理的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395e072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd47d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWithName(theSpecLib, index):\n",
    "    name = theSpecLib.names[index]\n",
    "    print(name)\n",
    "    bandC = theSpecLib.bands.centers\n",
    "    data = theSpecLib.spectra\n",
    "    plt.plot(bandC,data[index])\n",
    "\n",
    "def getIndex(theSpecLib, strFirst, strLast):\n",
    "    firstIndex = theSpecLib.names.index(strFirst)\n",
    "    lastIndex = theSpecLib.names.index(strLast)\n",
    "    return (firstIndex, lastIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3af1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecLib2287 = spl.envi.open(r'./aster/mineral_jhu_nicolet_2287.hdr')\n",
    "names = SpecLib2287.names\n",
    "\n",
    "doloFirstDataIndex = names.index(\"Dolomite CaMg(CO3)2 [carbonate-none-coarse-dolomi1]\")\n",
    "doloLastDataIndex = names.index(\"Dolomite CaMg(CO3)2 [carbonate-none-solid-dolomi3]\")\n",
    "oliFirstDataIndex = names.index(\"Olivine (Fo11) (Fe+2 Mg)2SiO4 [silicate-nesosilicate-fine-olivi10]\")\n",
    "oliLastDataIndex = names.index(\"Olivine (Fo92) (Fe+2 Mg)2SiO4 [silicate-nesosilicate-solid-olivin13]\")\n",
    "\n",
    "doloIndex = getIndex(SpecLib2287 ,\"Dolomite CaMg(CO3)2 [carbonate-none-coarse-dolomi1]\", \"Dolomite CaMg(CO3)2 [carbonate-none-solid-dolomi3]\")\n",
    "oliIndex = getIndex(SpecLib2287 ,\"Olivine (Fo11) (Fe+2 Mg)2SiO4 [silicate-nesosilicate-fine-olivi10]\", \"Olivine (Fo92) (Fe+2 Mg)2SiO4 [silicate-nesosilicate-fine-olivin1]\")\n",
    "\n",
    "trainData1 = SpecLib2287.spectra[doloIndex[0]:doloIndex[1]] \n",
    "trainData2 = SpecLib2287.spectra[oliIndex[0]:oliIndex[1]]\n",
    "trainData = numpy.vstack((trainData1, trainData2))\n",
    "# trainTensor = torch.Tensor(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa520618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cb7434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918e8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes():\n",
    "    return (['Oli', 'Dolo'], {'Oli': 0, 'Dolo': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07497a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oli', 'Dolo']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_classes()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "fa76892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个需要好好看，有可能会有不少问题！\n",
    "\n",
    "\n",
    "# Write a custom dataset class (inherits from torch.utils.data.Dataset)\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. Subclass torch.utils.data.Dataset\n",
    "class dataLoaderCustom(Dataset):\n",
    "    \n",
    "    # 2. Initialize with a targ_dir and transform (optional) parameter\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        \n",
    "        # 3. Create class attributes\n",
    "        # Get all image paths\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\")) \n",
    "        # Setup transforms\n",
    "        self.transform = transform\n",
    "        # Create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = find_classes()\n",
    "    \n",
    "#     # 4. Make function to load images\n",
    "#     def load_image(self, index: int) -> Image.Image:\n",
    "#         \"Opens an image via a path and returns it.\"\n",
    "#         image_path = self.paths[index]\n",
    "#         return Image.open(image_path) \n",
    "    \n",
    "    \n",
    "    # 4. Make function to load SEPC!!!!!!!!!!!!!\n",
    "    def load_spec(self, index: int):\n",
    "#         \"Opens an image via a path and returns it.\"\n",
    "#         image_path = self.paths[index]\n",
    "        return trainData[index]\n",
    "    \n",
    "    \n",
    "    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(trainData)\n",
    "    \n",
    "    \n",
    "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        \n",
    "        spec = self.load_spec(index)\n",
    "        \n",
    "        if index < 10:\n",
    "            class_name, class_idx = \"Oli\", 0\n",
    "        else:\n",
    "            class_name, class_idx = \"Dolo\", 1\n",
    "        \n",
    "#         class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpeg\n",
    "        \n",
    "#         class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(spec), class_idx # return data, label (X, y)\n",
    "        else:\n",
    "            return spec, class_idx # return data, label (X, y)\n",
    "    \n",
    "    \n",
    "#     def check():\n",
    "#         print(self.class)\n",
    "#         print(self.class_idx)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e1547c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_custom = dataLoaderCustom(targ_dir='train_dir', transform=torch.Tensor)\n",
    "\n",
    "\n",
    "# train_data_custom.load_spec(12), train_data_custom.__len__(), train_data_custom.__getitem__(19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "52780598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x20010cd7ee0>"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader_custom = DataLoader(dataset=train_data_custom, # use custom created train Dataset\n",
    "                                     batch_size=1, # how many samples per batch?\n",
    "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
    "                                     shuffle=True) # shuffle the data?\n",
    "train_dataloader_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "7aef1888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 2287]) -> [batch_size, color_channels, height, width]\n",
      "Label shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "spec_custom, label_custom = next(iter(train_dataloader_custom))\n",
    "\n",
    "print(f\"Image shape: {spec_custom.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label_custom.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdb91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "db7844f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "class isOliClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "#         modelVan = nn.Linear(2287, 4) # 输入特征数为2，输出特征数为1\n",
    "        \n",
    "        self.fc1 = nn.Linear(2287, 64)\n",
    "#         self.fc2 = nn.Linear(128, 64)\n",
    "#         self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "    \n",
    "#         print(self.fc1)\n",
    "    \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "bde8bbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n",
      "0.0008581769652664661\n",
      "175.85501098632812\n",
      "12.494743347167969\n",
      "15.063606262207031\n",
      "31.296154022216797\n",
      "1.311301275563892e-06\n",
      "15.022822380065918\n",
      "16.616193771362305\n",
      "6.057568073272705\n",
      "5.827556610107422\n",
      "0.34787994623184204\n",
      "0.0026280886959284544\n",
      "4.887569048150908e-06\n",
      "13.998854637145996\n",
      "20.005277633666992\n",
      "0.030921922996640205\n",
      "0.22494037449359894\n",
      "5.021701335906982\n",
      "0.0\n",
      "7.073669910430908\n",
      "6.214914321899414\n",
      "1.919238567352295\n",
      "0.34241974353790283\n",
      "0.006333636119961739\n",
      "0.004869387950748205\n",
      "9.13963794708252\n",
      "12.376642227172852\n",
      "0.0007104733376763761\n",
      "10.250435829162598\n",
      "0.0001134808044298552\n",
      "0.005305496044456959\n",
      "0.03254403546452522\n"
     ]
    }
   ],
   "source": [
    "### 这个被我过分简化了,现在重写!\n",
    "\n",
    "\n",
    "# 对上面定义的Classifier类进行实例化\n",
    "model = isOliClassifier()\n",
    "\n",
    "# 定义损失函数为负对数损失函数\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 优化方法为Adam梯度下降方法，学习率为0.003\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# 对训练集的全部数据学习15遍，这个数字越大，训练时间越长\n",
    "# epochs = 31\n",
    "\n",
    "# 将每次训练的训练误差和测试误差存储在这两个列表里，后面绘制误差变化折线图用\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "print('开始训练')\n",
    "\n",
    "\n",
    "# for i in trainTensor:\n",
    "\n",
    "for spec, labels in train_dataloader_custom:\n",
    "    \n",
    "    running_loss = 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 对64张图片进行推断，计算损失函数，反向传播优化权重，将损失求和\n",
    "\n",
    "    log_ps = model(spec.view(1,2287))\n",
    "    loss = criterion(log_ps, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    print(running_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "9e9d1c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n",
      "训练集学习次数: 1/100..  训练误差: 47.049..  测试误差: 0.655..  模型分类准确率: 0.688\n",
      "训练集学习次数: 2/100..  训练误差: 0.654..  测试误差: 0.652..  模型分类准确率: 0.688\n",
      "训练集学习次数: 3/100..  训练误差: 0.649..  测试误差: 0.647..  模型分类准确率: 0.688\n",
      "训练集学习次数: 4/100..  训练误差: 0.645..  测试误差: 0.642..  模型分类准确率: 0.688\n",
      "训练集学习次数: 5/100..  训练误差: 0.641..  测试误差: 0.639..  模型分类准确率: 0.688\n",
      "训练集学习次数: 6/100..  训练误差: 0.638..  测试误差: 0.637..  模型分类准确率: 0.688\n",
      "训练集学习次数: 7/100..  训练误差: 0.636..  测试误差: 0.634..  模型分类准确率: 0.688\n",
      "训练集学习次数: 8/100..  训练误差: 0.633..  测试误差: 0.632..  模型分类准确率: 0.688\n",
      "训练集学习次数: 9/100..  训练误差: 0.632..  测试误差: 0.630..  模型分类准确率: 0.688\n",
      "训练集学习次数: 10/100..  训练误差: 0.630..  测试误差: 0.629..  模型分类准确率: 0.688\n",
      "训练集学习次数: 11/100..  训练误差: 0.629..  测试误差: 0.627..  模型分类准确率: 0.688\n",
      "训练集学习次数: 12/100..  训练误差: 0.627..  测试误差: 0.626..  模型分类准确率: 0.688\n",
      "训练集学习次数: 13/100..  训练误差: 0.626..  测试误差: 0.626..  模型分类准确率: 0.688\n",
      "训练集学习次数: 14/100..  训练误差: 0.626..  测试误差: 0.624..  模型分类准确率: 0.688\n",
      "训练集学习次数: 15/100..  训练误差: 0.625..  测试误差: 0.624..  模型分类准确率: 0.688\n",
      "训练集学习次数: 16/100..  训练误差: 0.625..  测试误差: 0.624..  模型分类准确率: 0.688\n",
      "训练集学习次数: 17/100..  训练误差: 0.624..  测试误差: 0.623..  模型分类准确率: 0.688\n",
      "训练集学习次数: 18/100..  训练误差: 0.624..  测试误差: 0.623..  模型分类准确率: 0.688\n",
      "训练集学习次数: 19/100..  训练误差: 0.624..  测试误差: 0.623..  模型分类准确率: 0.688\n",
      "训练集学习次数: 20/100..  训练误差: 0.624..  测试误差: 0.622..  模型分类准确率: 0.688\n",
      "训练集学习次数: 21/100..  训练误差: 0.623..  测试误差: 0.622..  模型分类准确率: 0.688\n",
      "训练集学习次数: 22/100..  训练误差: 0.623..  测试误差: 0.622..  模型分类准确率: 0.688\n",
      "训练集学习次数: 23/100..  训练误差: 0.622..  测试误差: 0.622..  模型分类准确率: 0.688\n",
      "训练集学习次数: 24/100..  训练误差: 0.623..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 25/100..  训练误差: 0.622..  测试误差: 0.622..  模型分类准确率: 0.688\n",
      "训练集学习次数: 26/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 27/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 28/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 29/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 30/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 31/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 32/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 33/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 34/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 35/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 36/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 37/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 38/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 39/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 40/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 41/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 42/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 43/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 44/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 45/100..  训练误差: 0.624..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 46/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 47/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 48/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 49/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 50/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 51/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 52/100..  训练误差: 0.623..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 53/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 54/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 55/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 56/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 57/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 58/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 59/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 60/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 61/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 62/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 63/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 64/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 65/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 66/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 67/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 68/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 69/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 70/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 71/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 72/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 73/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 74/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 75/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 76/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 77/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 78/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 79/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 80/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 81/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 82/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 83/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 84/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 85/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 86/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 87/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 88/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 89/100..  训练误差: 0.623..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 90/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 91/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 92/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 93/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 94/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 95/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 96/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 97/100..  训练误差: 0.623..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 98/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 99/100..  训练误差: 0.622..  测试误差: 0.621..  模型分类准确率: 0.688\n",
      "训练集学习次数: 100/100..  训练误差: 0.621..  测试误差: 0.621..  模型分类准确率: 0.688\n"
     ]
    }
   ],
   "source": [
    "# 对上面定义的Classifier类进行实例化\n",
    "model = isOliClassifier()\n",
    "\n",
    "# 定义损失函数为负对数损失函数\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 优化方法为Adam梯度下降方法，学习率为0.003\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# 对训练集的全部数据学习15遍，这个数字越大，训练时间越长\n",
    "epochs = 100\n",
    "\n",
    "# 将每次训练的训练误差和测试误差存储在这两个列表里，后面绘制误差变化折线图用\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "print('开始训练')\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    # 对训练集中的所有图片都过一遍\n",
    "    for spec, labels in train_dataloader_custom:\n",
    "        # 将优化器中的求导结果都设为0，否则会在每次反向传播之后叠加之前的\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 对64张图片进行推断，计算损失函数，反向传播优化权重，将损失求和\n",
    "        log_ps = model(spec)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # 每次学完一遍数据集，都进行以下测试操作\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        # 测试的时候不需要开自动求导和反向传播\n",
    "        with torch.no_grad():\n",
    "            # 关闭Dropout\n",
    "            model.eval()\n",
    "            \n",
    "            # 对测试集中的所有图片都过一遍\n",
    "            for spec, labels in train_dataloader_custom:\n",
    "                # 对传入的测试集图片进行正向推断、计算损失，accuracy为测试集一万张图片中模型预测正确率\n",
    "                log_ps = model(spec)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                \n",
    "                # 等号右边为每一批64张测试图片中预测正确的占比\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        # 恢复Dropout\n",
    "        model.train()\n",
    "        # 将训练误差和测试误差存在两个列表里，后面绘制误差变化折线图用\n",
    "        train_losses.append(running_loss/len(train_dataloader_custom))\n",
    "        test_losses.append(test_loss/len(train_dataloader_custom))\n",
    "\n",
    "        print(\"训练集学习次数: {}/{}.. \".format(e+1, epochs),\n",
    "              \"训练误差: {:.3f}.. \".format(running_loss/len(train_dataloader_custom)),\n",
    "              \"测试误差: {:.3f}.. \".format(test_loss/len(train_dataloader_custom)),\n",
    "              \"模型分类准确率: {:.3f}\".format(accuracy/len(train_dataloader_custom)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "053419ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8064516129032258"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25/(6+25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d395d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fe0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f50aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b461b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40631256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de382a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872849ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090a39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "86cbced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 27\n",
    "\n",
    "if index < 10:\n",
    "    class_name, class_idx = \"Oli\", 0\n",
    "else:\n",
    "    class_name, class_idx = \"Dolo\", 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f25d3d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Dolo', 1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name, class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d5564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
